{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas scikit-learn matplotlib seaborn wordcloud tqdm PyPDF2 gensim smart-open nltk python-dotenv langchain langchain_community openai langchain_openai chromadb langchain_huggingface pypdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import getpass\n",
    "import chromadb\n",
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Preparation\n",
    "PATH_DB = './db'\n",
    "COLLECTION_NAME = 'policy'\n",
    "DIR_PATH = './documents/policy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma vectorstore and Embedding model\n",
    "\n",
    "Initialize existing persisting storage.\n",
    "\n",
    "IMPORTANT: make sure to have loaded some documents to the vector database. This can be done by running the ``load_data.py`` in /src."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "# Instantiate a persistent chroma client in the persist_directory.\n",
    "# This will automatically load any previously saved collections.\n",
    "# Learn more at docs.trychroma.com\n",
    "client_db = chromadb.PersistentClient(path=PATH_DB)\n",
    "\n",
    "embedder = OllamaEmbeddingFunction(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    url=\"http://localhost:11434/api/embeddings\",\n",
    ")\n",
    "\n",
    "# Get the collection.\n",
    "collection = client_db.get_collection(name=COLLECTION_NAME, embedding_function=embedder)\n",
    "collection.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval and generation: Create an agent2agent dialogue pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dummy version with meat-eating debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY') if 'OPENAI_API_KEY' in os.environ else getpass.getpass()\n",
    "\n",
    "# Initialize ChatOpenAI instances\n",
    "devil_agent = ChatOpenAI(api_key=openai.api_key, model=\"gpt-4o-mini\")\n",
    "angel_agent = ChatOpenAI(api_key=openai.api_key, model=\"gpt-4o-mini\")\n",
    "\n",
    "# These agents a real chatterboxes, they need some restrains\n",
    "output_length = 50\n",
    "\n",
    "# Define system prompts for the two agents\n",
    "devil_system_prompt = f\"\"\"\n",
    "You are the Devil's Advocate. You will have a debate with the Angel's Advocate. Your mission is to make your case that eating meat is ethically right. \n",
    "Always meet your opponent's most recent arguement first and indicate this by writing \"Reponse on opponent's arguement: \". \n",
    "Then continue by presenting a new argument to streghthen your own point of view, indicate your own view by writing \"New aguments made: \".\n",
    "You have a total of {output_length} words to give your response. Also, start every new sentence with a new row after a row break. \n",
    "\"\"\"\n",
    "\n",
    "angel_system_prompt = f\"\"\"\n",
    "You are the Angel's Advocate. You will have a debate with the Devil's Advocate. Your mission is to make the case that eating meat is ethically wrong. \n",
    "Always meet your opponent's most recent arguement first and indicate this by writing \"\\n Reponse on opponent's arguement: \". \n",
    "Then continue by presenting a new argument to streghthen your own point of view, indicate your own view by writing \"\\n New aguments made: \".\n",
    "You have a total of {output_length} words to give your response. Also, start every new sentence with a new row after a row break. \n",
    "\"\"\"\n",
    "\n",
    "# Define initial task prompt for the devil agent\n",
    "task_prompt = \"Discuss how eating meat is ethically right or wrong. You will start by making presenting your point of view on the matter.\"\n",
    "\n",
    "# Function to create a debate between the two agents\n",
    "def run_debate(devil_prompt, angel_prompt, task_prompt, num_rounds=3):\n",
    "    devil_message = task_prompt\n",
    "    dialogue = []\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        # Devil agent's turn\n",
    "        devil_response = devil_agent.invoke([{\"role\": \"system\", \"content\": devil_prompt}, {\"role\": \"user\", \"content\": devil_message}])\n",
    "        devil_message = devil_response.content\n",
    "        dialogue.append(f\"\\n \\n #####Devil: {devil_message}\")\n",
    "        \n",
    "        # Angel agent's turn\n",
    "        angel_response = angel_agent.invoke([{\"role\": \"system\", \"content\": angel_prompt}, {\"role\": \"user\", \"content\": devil_message}])\n",
    "        angel_message = angel_response.content\n",
    "        dialogue.append(f\"\\n \\n #####Angel: {angel_message}\")\n",
    "        \n",
    "        # Prepare for the next round\n",
    "        devil_message = angel_message\n",
    "\n",
    "    return dialogue\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "# Run the debate\n",
    "# debate_dialogue = run_debate(devil_system_prompt, angel_system_prompt, task_prompt, num_rounds=2)\n",
    "\n",
    "# Verbose: Print the full dialogue\n",
    "# for line in debate_dialogue:\n",
    "    # print(line)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Save the dialogue to a .txt file\n",
    "# current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# file_name = f\"debate_dialogue_{current_time}.txt\"\n",
    "# with open(file_name, \"w\") as file:\n",
    "#     for line in debate_dialogue:\n",
    "#         file.write(line + \"\\n\")\n",
    "#     file.write(f\"\\nTime taken: {elapsed_time:.2f} seconds\\n\")\n",
    "\n",
    "# print(f\"Debate dialogue saved to {file_name}\")\n",
    "# print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Could be extended by another LLM analysing an long debate script and summarize it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full version for loopholes [Work in progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(message, docs, is_angel=False, output_length=50):\n",
    "    \"\"\"Define system prompts for the two agents\"\"\"\n",
    "    \n",
    "    if not is_angel:\n",
    "        devil_system_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"name\": \"Devil\",\n",
    "                \"content\": f\"\"\"You are the Devil's Advocate. You will have a debate with the Angel's Advocate.\n",
    "                    Your task is to exploit loopholes in the university´s governing documents. Be specific and detailed on what you can exploit.\n",
    "                    You must build your arguments on the information given in the documents you have from the vector storage: {docs}\n",
    "                    Find any relevant documents and make a point based on the information in the document(s), don't forget to reference the source by stating a quote from the document and the document name.\n",
    "\n",
    "                    Start with \"\\n### Devil:\\n\" followed by your response.\n",
    "                    Always meet your opponent's most recent arguement first.\n",
    "                    Then continue by presenting a new argument to streghthen your own point of view.\n",
    "                    Don't repeat or suggest similar previous arguments.\n",
    "                    You have a total of {output_length} words to give your response.\n",
    "                    \"\"\"\n",
    "            }, \n",
    "            {\"role\": \"user\", \"content\": f\"Here's the dialogue: {message}\"}\n",
    "        ]\n",
    "        return devil_system_prompt\n",
    "    else:\n",
    "        angel_system_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"name\": \"Angel\",\n",
    "                \"content\": f\"\"\"\n",
    "                    You are the Angel's Advocate. You will have a debate with the Devil's Advocate. \n",
    "                    Your task is to prevent the exploitation of loopholes in the university´s governing documents.\n",
    "                    You must build your arguments on the information given in the documents you have from the vector storage: {docs}\n",
    "                    Find the relevant document for the matter, make a point based on the information given in it and reference the source by stating a quote from the documents and the document name.\n",
    "\n",
    "                    Start with \"\\n### Angel:\\n\" followed by your response.\n",
    "                    Always meet your opponent's most recent arguement first\".\n",
    "                    Then continue by presenting a new argument to streghthen your own point of view.\n",
    "                    Don't repeat or suggest similar previous arguments.\n",
    "                    You have a total of {output_length} words to give your response.\n",
    "                \"\"\"\n",
    "            }, \n",
    "            {\"role\": \"user\", \"content\": f\"Here's the dialogue: {message}\"}\n",
    "        ]\n",
    "    return angel_system_prompt\n",
    "\n",
    "def stream_response(response: str) -> str:\n",
    "    \"\"\"Stream response to output.\"\"\"\n",
    "    message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            message += (chunk.choices[0].delta.content)\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "    print(\"\\n\\n\")\n",
    "    return message\n",
    "\n",
    "def get_response(agent: OpenAI, model: str, temperature: float = 0.8, **kwargs) -> str:\n",
    "    response = agent.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=build_prompt(**kwargs),\n",
    "        stream=True,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    message = stream_response(response)\n",
    "    return message\n",
    "\n",
    "def run_debate(task_prompt, num_rounds=3):\n",
    "    \"\"\"Function to create a debate between the two agents\"\"\"\n",
    "    \n",
    "    # Set OpenAI API key\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY') if 'OPENAI_API_KEY' in os.environ else getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "    devil_agent = OpenAI()\n",
    "    angel_agent = OpenAI()\n",
    "    boss_agent = OpenAI()\n",
    "    \n",
    "    # MODEL = \"gpt-4o-mini\"\n",
    "    MODEL = \"gpt-3.5-turbo\"\n",
    "    \n",
    "    # Query the collection to get the 5 most relevant results\n",
    "    docs = collection.query(\n",
    "        query_texts=[task_prompt], n_results=5, include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "\n",
    "    if not docs:\n",
    "        raise ValueError(f\"No relevant docs were retrieved!\")\n",
    "        \n",
    "    message = task_prompt\n",
    "    dialogue = [message]\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"__________Turn number {round_num+1}__________\")\n",
    "        \n",
    "        ## Devil agent's turn\n",
    "        message = get_response(devil_agent, MODEL, message=dialogue, docs=docs, is_angel=False)\n",
    "        dialogue.append(message)\n",
    "        \n",
    "        ## Angel agent's turn\n",
    "        message = get_response(angel_agent, MODEL, message=dialogue, docs=docs, is_angel=True)\n",
    "        dialogue.append(message)\n",
    "\n",
    "        ## Boss agent's take on the arguments.\n",
    "        boss_response = boss_agent.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"\n",
    "                    Analyze the following debate arguments {dialogue}.\n",
    "                    Start with \"\\n### Boss:\\n\" followed by your response.\n",
    "                    If the debate arguments are repetitive and at stand-still, respond with: Case closed.\n",
    "                \"\"\"\n",
    "            }],\n",
    "            stream=True\n",
    "        )\n",
    "        boss_message = stream_response(boss_response)\n",
    "        if \"Case closed\" in boss_message:\n",
    "            print(\"=> Terminating...\")\n",
    "            dialogue.append(boss_message)\n",
    "            return \"\\n\\n\".join(dialogue)\n",
    "\n",
    "    return \"\\n\\n\".join(dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TASK: \n",
      "    Discuss what is allowed and important to think about for the case of when a Chalmers employee wants to invite a professor with the purpose of recruitment.\n",
      "    What and how much can Chalmers pay for such as flights, food, drinks?\n",
      "    Moreover, what do Chalmers offer such as relocation, familiy jobs, etc.\n",
      "\n",
      "__________Turn number 1__________\n",
      "### Devil:\n",
      "The university's governing document states, \"Redan anställd fakultet ska premieras med möjlighet till ökad basfinansiering när man presterar excellent... Genomföra en rekryteringspilot med erbjudande om bra villkor till externa kandidater.\" Chalmers can exploit this by offering attractive financial incentives to recruit professors, potentially stretching the budget limits.\n",
      "\n",
      "\n",
      "### Angel:\n",
      "The university's commitment to providing increased funding to existing faculty for excellence does not imply unlimited budget flexibility for recruiting external candidates. As stated, the focus is on rewarding current staff. Thus, Chalmers must ensure responsible financial management to avoid exceeding available resources. \n",
      "\n",
      "### Angel:\n",
      "Additionally, the document emphasizes the importance of attracting and developing world-leading faculty members. Chalmers should prioritize sustainable recruitment practices that align with long-term strategic goals rather than solely focusing on short-term financial incentives. Quality and strategic fit should guide recruitment decisions to maintain academic excellence.\n",
      "\n",
      "\n",
      "### Boss:\n",
      "Chalmers must carefully consider the balance between attracting top talent and responsible financial management. While it is important to offer competitive financial incentives to external candidates, we must ensure that we stay within budget limits and prioritize the long-term sustainability of our recruitment practices. Quality over quantity should guide our decisions in order to maintain Chalmers' academic excellence.\n",
      "\n",
      "\n",
      "__________Turn number 2__________\n",
      "### Devil:\n",
      "The document also mentions the need to \"öka basfinansieringen till redan anställd fakultet.\" By recruiting external candidates with attractive benefits, Chalmers can argue that this strategy indirectly enhances the existing faculty's funding by elevating the overall academic environment and potentially attracting more resources.\n",
      "\n",
      "\n",
      "\n",
      "### Angel:\n",
      "The document specifies the need to prioritize existing faculty by increasing their funding for excellence. This underscores the importance of maintaining a balanced approach to recruitment expenses. Chalmers must focus on sustainable practices aligned with long-term goals to uphold academic quality while managing financial resources responsibly.\n",
      "\n",
      "### Angel:\n",
      "Furthermore, Chalmers' commitment to attracting world-leading faculty members should guide recruitment strategies, emphasizing quality and strategic alignment over short-term financial incentives. By prioritizing excellence and fit within the institution's goals, Chalmers can ensure long-term academic success and reputation.\n",
      "\n",
      "\n",
      "### Boss:\n",
      "Chalmers must carefully balance the need to attract top talent with responsible financial management. While the university's governing document allows for increased funding to existing faculty for excellence and mentions the potential benefits of recruiting external candidates, it is crucial to ensure that recruitment practices align with long-term strategic goals. Quality and strategic fit should be the primary considerations in recruitment decisions to uphold academic excellence and reputation.\n",
      "\n",
      "Case closed.\n",
      "\n",
      "\n",
      "=> Terminating...\n",
      "=> Debate dialogue saved to out/debate_dialogue_20240731_123510.txt\n",
      "Time taken: 11.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Define initial task prompt for the devil agent\n",
    "# task_prompt = \"Discuss why the policy does allow you to drink beer during working hours. You will start by making presenting your point of view on the matter.\"\n",
    "task_prompt = \"\"\"\n",
    "    Discuss what is allowed and important to think about for the case of when a Chalmers employee wants to invite a professor with the purpose of recruitment.\n",
    "    What and how much can Chalmers pay for such as flights, food, drinks?\n",
    "    Moreover, what do Chalmers offer such as relocation, familiy jobs, etc.\n",
    "\"\"\"\n",
    "\n",
    "# Run the debate\n",
    "print(\"# TASK:\", task_prompt)\n",
    "debate_dialogue = run_debate(task_prompt, num_rounds=4)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Save the dialogue to a .txt file\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f\"out/debate_dialogue_{current_time}.txt\"\n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(debate_dialogue)\n",
    "    file.write(f\"\\nTime taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(f\"=> Debate dialogue saved to {file_name}\")\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Could be extended by another LLM analysing an long debate script and summarize it. Or be the judge on who won the debate and what the answer should be.  \n",
    "# For a more sophisticated solution would include a expert panel that could vote on who would be the winner of the debate with different areas/principles to investigate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
